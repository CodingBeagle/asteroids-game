# Pipeline Overview

Application -> Vertex Shader -> Tessellation Shaders -> Geometry Shader -> Rasterization -> Fragment Shader -> Pixel Operations.

## Tessellation

The Tessellation stage was added in OpenGL 4.0.

The Tessellation stage provides a tessellator, which can generate a large number of triangles, typically as a grid.

## Geometry Shader

The vertex shader gives us the ability to manipulate a single vertex at a time.
The fragment shader gives us the ability to manipulate a single fragment (pixel) at a time.

The geometry shader, on the other hand, allows us to manipulate one primitive at a time. It gives access to the three vertices making up a triangle simuntaniously. The geometry shader also has the ability to add extra triangles.

## Rasterization

In the Rasterization stage, primitives such as lines, points, or triangles are converted into sets of pixels.

Ultimately, the 3D world described through vertices, triangles, colors, and so on, needs to be converted to, and displayed, on a 2D monitor.

A monitor is made of up a **raster** (a rectangular array of pixels).

So, OpenGl will rasterize a 3D object by converting its primitives (which are usually rectangles) into **fragments**, where a fragment is the piece of information about a pixel.

The rasterize interpolates between 3 vertices, first pair-wise, so that you end up with lines between the vertices. Then, depending on the options you have given to OpenGL, the rasterizer will also "fill up" the triangle's inside by interpolating. This is the default process by which 3D models are rendered as being solid. To achieve a wireframe rendering, you stop rasterization right after interpolating lines between the vertices.

## Fragment Shader

The purpose of the fragment shader is to assign color to the rasterized pixels.

## Pixel Operations

*Hidden Surface Removal* = The process of hiding pixels of objects that are behind other objects, or hiding the back of objects themselves.

The pixel operations stage is configurable, but not programmable.

HSR is done in OpenGL by use of two buffers:

- Color Buffer
  - Colors generated by the fragment shader are placed in the color buffer. The color buffer is what is ultimately written to the screen.
- Depth Buffer
  - Before a scene is rendered, the depth buffer is filled with values represening the maximum depth.
  - When a pixel color is output by the fragment shader, its distance from the viewer is calculated.
  - If the computed distance is *less than* the distance stored in the depth buffer for that pixels,
    - The pixel color is replaced
    - The distance replaces the value in the depth buffer.
    - In all other cases, the pixel is discarded.
    - This is known as the **Z-Buffer Algorithm**.

These buffers are the same size as the raster (so every buffer has an entry for every pixel on the screen).